{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current wd /Users/carlos/Documents/Peccala/deepL_tests\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "print(f\"current wd {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/11hy697j7mv487fs334bjwvr0000gp/T/ipykernel_39319/3524868131.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tr_tensor = torch.tensor(y_tr_t, dtype=torch.long)\n",
      "/var/folders/0f/11hy697j7mv487fs334bjwvr0000gp/T/ipykernel_39319/3524868131.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_tensor = torch.tensor(y_val_t, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Define the directory containing the .npy files\n",
    "directory_path = \"data_deep_learning/series_data\"\n",
    "\n",
    "tst_perc = 0.05\n",
    "val_perc = 0.1\n",
    "\n",
    "seq_length = 32\n",
    "d_model = 80\n",
    "n_head = 2\n",
    "max_len = 3000\n",
    "ffn_hidden = 60\n",
    "n_layers = 2\n",
    "n_classes = 1\n",
    "drop_prob = 0.4\n",
    "details = False\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "patience = 14\n",
    "model = None\n",
    "\n",
    "'''logging.basicConfig(\n",
    "    filename=\"progress.log\",  # File where logs will be saved\n",
    "    level=logging.INFO,       # Log level (e.g., DEBUG, INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Log format\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"  # Timestamp format\n",
    "    import sys\n",
    "\n",
    "# Redirect stdout to a file\n",
    "\n",
    ")'''\n",
    "\n",
    "if True : #with open(\"progress.log\", \"w\") as f:\n",
    "    #sys.stdout = f\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        print(\"Starting the process...\")\n",
    "        key = file_name.split('.')[0].replace(\"&\",\"/\")\n",
    "        if file_name.endswith(\".npy\") and \"DOGE\" in key:  \n",
    "            #key = file_name.split('.')[0].replace(\"&\",\"/\")\n",
    "            print(f\"Processing series {key}...\")\n",
    "\n",
    "            data = np.load(directory_path+\"/\"+file_name)\n",
    "            X=data[:,:-1]\n",
    "            y=data[:,-1]\n",
    "            del data\n",
    "            for i in range(X.shape[0]):\n",
    "                if not np.isnan(sum(X[i, 72:])):\n",
    "                    print(f\" not nan's at {i}\")\n",
    "                    l_ind = i\n",
    "                    break\n",
    "            for i in range(l_ind, X.shape[0]):\n",
    "                if np.isnan(sum(X[i, 72:])):\n",
    "                    print(f\" at {key} NaNs at {i}\")\n",
    "            if l_ind > X.shape[0] - 6000:\n",
    "                X=X[l_ind:, :]\n",
    "                y=y[l_ind:]\n",
    "            else:    \n",
    "                X=X[-6000:, :]\n",
    "                y=y[-6000:]\n",
    "            \n",
    "            n_X = norm_mts_with_window(X, window_size=30)    \n",
    "            n_X = create_seq_from_ts(n_X, seq_length)\n",
    "            print(f\"norm and turning into seqences complete.\")\n",
    "            n_y=y[seq_length-1:]    \n",
    "            \n",
    "            ind_tst = int(n_X.shape[0] * tst_perc)\n",
    "            ind_val = int(n_X.shape[0] * val_perc)\n",
    "            \n",
    "            X_tr, X_val, X_tst = n_X[: -(ind_tst + ind_val),:,:], n_X[-(ind_tst + ind_val):-ind_tst,:,:], n_X[-ind_tst:,:,:] \n",
    "            y_tr, y_val, y_tst = n_y[: -(ind_tst + ind_val)], n_y[-(ind_tst + ind_val):-ind_tst], n_y[-ind_tst:] \n",
    "\n",
    "            X_tr_t = torch.tensor(X_tr, dtype=torch.float32).to(device)\n",
    "            y_tr_t = torch.tensor(y_tr, dtype=torch.float32).to(device)\n",
    "            X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "            y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "            X_tst_t = torch.tensor(X_tst, dtype=torch.float32).to(device)\n",
    "            y_tst_t = torch.tensor(y_tst, dtype=torch.float32).to(device)\n",
    "\n",
    "            #scale targets to lie between 1 and 0\n",
    "            y_tr_t = (y_tr_t +1) / 2\n",
    "            y_val_t = (y_val_t +1) / 2\n",
    "            y_tst_t = (y_tst_t +1) / 2\n",
    "            \n",
    "            SEED = 77\n",
    "            random.seed(SEED)\n",
    "            np.random.seed(SEED)\n",
    "            torch.manual_seed(SEED)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.manual_seed(SEED)\n",
    "                torch.cuda.manual_seed_all(SEED)\n",
    "                torch.backends.cudnn.deterministic = True\n",
    "                torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "            \n",
    "            best_v_acc = 0\n",
    "            n_noimprov = 0\n",
    "            best_model_params = None\n",
    "\n",
    "            y_tr_tensor = torch.tensor(y_tr_t, dtype=torch.long)\n",
    "            y_val_tensor = torch.tensor(y_val_t, dtype=torch.long)\n",
    "\n",
    "\n",
    "            # Prepare data loaders\n",
    "            train_dataset = TensorDataset(X_tr_t, y_tr_tensor)\n",
    "            val_dataset = TensorDataset(X_val_t, y_val_tensor)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            if not model:\n",
    "                print(f\"Creating the model.\")   \n",
    "                model = Transformer(\n",
    "                    device=device,\n",
    "                    d_model=d_model,\n",
    "                    n_head=n_head,\n",
    "                    max_len=max_len,\n",
    "                    seq_len=seq_length,\n",
    "                    ffn_hidden=ffn_hidden,\n",
    "                    n_layers=n_layers,\n",
    "                    drop_prob=drop_prob,\n",
    "                    details=details\n",
    "                ).to(device)\n",
    "            pos_weight = len(y_tr_t) / sum(y_tr_t)  # Assumes y_tr_t is binary {0, 1}\n",
    "            neg_weight = len(y_tr_t) / (len(y_tr_t) - sum(y_tr_t))\n",
    "\n",
    "            # Use a tensor to represent positive and negative weights\n",
    "            class_weight = torch.tensor([neg_weight, pos_weight]).to(device)\n",
    "\n",
    "            # Update criterion\n",
    "            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "            print(f\"------------------for series {key} training loop\")\n",
    "            # Training loop\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                for X_batch, y_batch in train_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "                    # Ensure y_batch is of the correct type\n",
    "                    y_batch = y_batch.float()\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "                    # Compute predictions and accuracy\n",
    "                    probabilities = torch.sigmoid(outputs)\n",
    "                    predicted = (probabilities > 0.5).float()\n",
    "                    correct += (predicted == y_batch).sum().item()\n",
    "                    total += y_batch.size(0)\n",
    "\n",
    "                train_loss /= len(train_loader.dataset)\n",
    "                train_accuracy = 100 * correct / total\n",
    "                \n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, y_batch in val_loader:\n",
    "                        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "                        y_batch = y_batch.float()\n",
    "\n",
    "                        outputs = model(X_batch)\n",
    "                        loss = criterion(outputs, y_batch)\n",
    "\n",
    "                        val_loss += loss.item() * X_batch.size(0)\n",
    "                        probabilities = torch.sigmoid(outputs)\n",
    "                        predicted = (probabilities > 0.5).float()\n",
    "                        correct += (predicted == y_batch).sum().item()\n",
    "                        total += y_batch.size(0)\n",
    "\n",
    "                val_loss /= len(val_loader.dataset)\n",
    "                val_accuracy = 100 * correct / total\n",
    "                \n",
    "                if train_accuracy > 90:\n",
    "                    if val_accuracy > best_v_acc:\n",
    "                        best_v_acc = val_accuracy\n",
    "                        best_model_params = copy.deepcopy(model.state_dict())\n",
    "                        n_noimprov = 0\n",
    "                    else:\n",
    "                        n_noimprov +=1\n",
    "                            \n",
    "                if n_noimprov > patience and best_model_params: #best_model_params is not None\n",
    "                    print(f\"Early stopping triggered, best acc on val data {best_v_acc}\")   \n",
    "                    break \n",
    "\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "            print(\"Training complete.\")\n",
    "        \n",
    "        \n",
    "sys.stdout = sys.__stdout__\n",
    "print(\"Progress log has been written to progress.log\")        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "#X=X[-3000:,:]\n",
    "#y=y[-3000:]\n",
    "#print(f\"x shape {X.shape}, y s {y.shape}\")\n",
    "#sys.stdout = sys.__stdout__\n",
    "print(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_X = norm_mts_with_window(X, window_size=30)\\nprint(\"Normalized data shape:\", n_X.shape)\\n\\nseq_length = 32\\n\\nn_X = create_seq_from_ts(n_X, seq_length)\\nn_y=y[seq_length-1:]\\nprint(\"X shape\", n_X.shape)\\nprint(\"y shape \", n_y.shape)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm_mts_with_window(data, window_size=30):\n",
    "    \"\"\"\n",
    "    Normalize a multivariate time series so that each component of the vector has\n",
    "    a standard deviation of 1 within a sliding window lokking back in time.\n",
    "    If window size is 1 does nothing.\n",
    "\n",
    "    Returns np.array normalized time series data with the same shape as input.\n",
    "    \"\"\"\n",
    "    t_steps, num_features = data.shape\n",
    "    normalized_data = np.zeros_like(data)\n",
    "\n",
    "    for t in range(t_steps):\n",
    "        start_i = max(0, t - window_size + 1)\n",
    "        end_i = t + 1\n",
    "        window = data[start_i:end_i]\n",
    "        std = np.std(window, axis=0)\n",
    "        mean = np.mean(window, axis=0)\n",
    "        std[std == 0] = 1\n",
    "        normalized_data[t] = (data[t])/ std\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "#function to create tensor with seg_length of backward steps\n",
    "def create_seq_from_ts(data, seq_length):\n",
    "    \"\"\"\n",
    "    Function that returns the vectors with corresponding seq_length,\n",
    "    of observations in the past.\n",
    "\n",
    "    Output should have shape (data.shape[0] - seq_length, seq_length, num_features)\n",
    "\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        # Extract the sequence of features\n",
    "        sequence = data[i:i+seq_length]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "\n",
    "    return sequences\n",
    "\n",
    "# Normalize with a sliding window of size 30\n",
    "'''n_X = norm_mts_with_window(X, window_size=30)\n",
    "print(\"Normalized data shape:\", n_X.shape)\n",
    "\n",
    "seq_length = 32\n",
    "\n",
    "n_X = create_seq_from_ts(n_X, seq_length)\n",
    "n_y=y[seq_length-1:]\n",
    "print(\"X shape\", n_X.shape)\n",
    "print(\"y shape \", n_y.shape)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the data to save RAM ??\n",
    "sequences = sequences[-3000:,:,:]\n",
    "print(f\"Sequences shape {sequences.shape}\")\n",
    "del n_data\n",
    "del data\n",
    "target_btc_f=target_btc_f[-5000:]\n",
    "print(f\"Target shape {target_btc_f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m tst_perc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m      4\u001b[0m val_perc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m ind_tst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mn_X\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m tst_perc)\n\u001b[1;32m      6\u001b[0m ind_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m val_perc)\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_X' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tst_perc = 0.05\n",
    "val_perc = 0.1\n",
    "ind_tst = int(n_X.shape[0] * tst_perc)\n",
    "ind_val = int(n_X.shape[0] * val_perc)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#split train, val, test\n",
    "X_tr, X_val, X_tst = n_X[: -(ind_tst + ind_val),:,:], n_X[-(ind_tst + ind_val):-ind_val,:,:], n_X[-ind_val:,:,:] \n",
    "y_tr, y_val, y_tst = n_y[: -(ind_tst + ind_val)], n_y[-(ind_tst + ind_val):-ind_val], n_y[-ind_val:] \n",
    "\n",
    "X_tr_t = torch.tensor(X_tr, dtype=torch.float32).to(device)\n",
    "y_tr_t = torch.tensor(y_tr, dtype=torch.float32).to(device)\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "X_tst_t = torch.tensor(X_tst, dtype=torch.float32).to(device)\n",
    "y_tst_t = torch.tensor(y_tst, dtype=torch.float32).to(device)\n",
    "\n",
    "#scale targets to lie between 1 and 0\n",
    "y_tr_t = (y_tr_t +1) / 2\n",
    "y_val_t = (y_val_t +1) / 2\n",
    "y_tst_t = (y_tst_t +1) / 2\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"X_tr_tensor shape: {X_tr_t.shape}\")\n",
    "print(f\"y_tr_tensor shape: {y_tr_t.shape}\")\n",
    "print(f\"X_tst_tensor shape: {X_tst_t.shape}\")\n",
    "print(f\"y_tst_tensor shape: {y_tst_t.shape}\")\n",
    "print(f\"y_val_tensor: {y_tr_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,device, d_model=100, n_head=4, max_len=500, seq_len=30,\n",
    "                 ffn_hidden=128, n_layers=4, drop_prob=0.1, details =False):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.details = details\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=145,\n",
    "            out_features=d_model\n",
    "            )\n",
    "\n",
    "        self.pos_emb = PostionalEncoding( max_seq_len=max_len,batch_first=False, d_model=d_model, dropout=0.1) #try different values of drupout?\n",
    "        self.encoder = Encoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers,\n",
    "                               details=details,\n",
    "                               device=device)\n",
    "        self.classHead = ClassificationHead(seq_len=seq_len,d_model=d_model,details=details,n_classes=1)\n",
    "\n",
    "    def forward(self, src ):\n",
    "        if self.details: print('before input layer: '+ str(src.size()) )\n",
    "        src= self.encoder_input_layer(src)\n",
    "        if self.details: print('after input layer: '+ str(src.size()) )\n",
    "        src= self.pos_emb(src)\n",
    "        if self.details: print('after pos_emb: '+ str(src.size()) )\n",
    "        enc_src = self.encoder(src)\n",
    "        cls_res = self.classHead(enc_src)\n",
    "        if self.details: print('after cls_res: '+ str(cls_res.size()) )\n",
    "        return cls_res\n",
    "\n",
    "\n",
    "class PostionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout: float=0.1,\n",
    "        max_seq_len: int=5000,\n",
    "        d_model: int=512,\n",
    "        batch_first: bool=False    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batch_first = batch_first\n",
    "        self.x_dim = 1 if batch_first else 0\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(self.x_dim)]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob,details):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head, details=details)\n",
    "        self.norm1 = LayerNorm(d_model=d_model)\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "        self.details = details\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model=d_model)\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. compute self attention\n",
    "        _x = x\n",
    "        x = self.attention(q=x, k=x, v=x )\n",
    "\n",
    "        if self.details: print('in encoder layer : '+ str(x.size()))\n",
    "        # 2. add and norm\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        if self.details: print('in encoder after norm layer : '+ str(x.size()))\n",
    "        # 3. positionwise feed forward network\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "\n",
    "        if self.details: print('in encoder after ffn : '+ str(x.size()))\n",
    "        # 4. add and norm\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + _x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, ffn_hidden, n_head, n_layers,\n",
    "                 drop_prob, details, device):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n",
    "                                                  ffn_hidden=ffn_hidden,\n",
    "                                                  n_head=n_head\n",
    "                                                  ,details=details,\n",
    "                                                  drop_prob=drop_prob)\n",
    "                                     for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x ):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self,d_model, seq_len , details, n_classes: int = 1):\n",
    "      super().__init__()\n",
    "      self.norm = nn.LayerNorm(d_model)\n",
    "      self.details = details\n",
    "      #self.flatten = nn.Flatten()\n",
    "      self.seq = nn.Sequential( nn.Flatten() , nn.Linear(d_model * seq_len , 512) ,nn.ReLU(),nn.Linear(512, 256)\n",
    "                               ,nn.ReLU(),nn.Linear(256, 128),nn.ReLU(),nn.Linear(128, n_classes))\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "      if self.details:  print('in classification head : '+ str(x.size()))\n",
    "      x= self.norm(x)\n",
    "      #x= self.flatten(x)\n",
    "      x= self.seq(x)\n",
    "      if self.details: print('in classification head after seq: '+ str(x.size()))\n",
    "      return x\n",
    "  \n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_head, details):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.attention = ScaleDotProductAttention( details=details)\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_concat = nn.Linear(d_model, d_model)\n",
    "        self.details = details\n",
    "\n",
    "    def forward(self, q, k, v ):\n",
    "        # 1. dot product with weight matrices\n",
    "\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "\n",
    "        if self.details: print('in Multi Head Attention Q,K,V: '+ str(q.size()))\n",
    "        # 2. split tensor by number of heads\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "\n",
    "        if self.details: print('in splitted Multi Head Attention Q,K,V: '+ str(q.size()))\n",
    "        # 3. do scale dot product to compute similarity\n",
    "        out, attention = self.attention(q, k, v )\n",
    "\n",
    "        if self.details: print('in Multi Head Attention, score value size: '+ str(out.size()))\n",
    "        # 4. concat and pass to linear layer\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "\n",
    "        # 5. visualize attention map\n",
    "        # TODO : we should implement visualization\n",
    "\n",
    "        if self.details: print('in Multi Head Attention, score value size after concat : '+ str(out.size()))\n",
    "        return out\n",
    "\n",
    "    def split(self, tensor):\n",
    "        \"\"\"\n",
    "        split tensor by number of head\n",
    "\n",
    "        :param tensor: [batch_size, length, d_model]\n",
    "        :return: [batch_size, head, length, d_tensor]\n",
    "        \"\"\"\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "        d_tensor = d_model // self.n_head\n",
    "        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n",
    "        # it is similar with group convolution (split by number of heads)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        \"\"\"\n",
    "        inverse function of self.split(tensor : torch.Tensor)\n",
    "\n",
    "        :param tensor: [batch_size, head, length, d_tensor]\n",
    "        :return: [batch_size, length, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ScaleDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    compute scale dot product attention\n",
    "\n",
    "    Query : given sentence that we focused on (decoder)\n",
    "    Key : every sentence to check relationship with Qeury(encoder)\n",
    "    Value : every sentence same with Key (encoder)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, details):\n",
    "        super(ScaleDotProductAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.details = details\n",
    "    def forward(self, q, k, v ,e=1e-12):\n",
    "        # input is 4 dimension tensor\n",
    "        # [batch_size, head, length, d_tensor]\n",
    "        batch_size, head, length, d_tensor = k.size()\n",
    "\n",
    "        # 1. dot product Query with Key^T to compute similarity\n",
    "        k_t = k.transpose(2, 3)  # transpose\n",
    "\n",
    "        if self.details: print('in Scale Dot Product, k_t size: '+ str(k_t.size()))\n",
    "        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n",
    "\n",
    "\n",
    "        if self.details: print('in Scale Dot Product, score size: '+ str(score.size()))\n",
    "        # 3. pass them softmax to make [0, 1] range\n",
    "        score = self.softmax(score)\n",
    "\n",
    "        if self.details: print('in Scale Dot Product, score size after softmax : '+ str(score.size()))\n",
    "\n",
    "        if self.details: print('in Scale Dot Product, v size: '+ str(v.size()))\n",
    "        # 4. multiply with Value\n",
    "        v = score @ v\n",
    "\n",
    "        if self.details: print('in Scale Dot Product, v size after matmul: '+ str(v.size()))\n",
    "        return v, score\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        # '-1' means last dimension.\n",
    "\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 32\n",
    "d_model = 60\n",
    "n_head = 2\n",
    "max_len = 3000\n",
    "ffn_hidden = 60\n",
    "n_layers = 2\n",
    "n_classes = 1\n",
    "drop_prob = 0.4\n",
    "details = False\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "patience = 14\n",
    "model = Transformer(\n",
    "                    device=\"cpu\",\n",
    "                    d_model=d_model,\n",
    "                    n_head=n_head,\n",
    "                    max_len=max_len,\n",
    "                    seq_len=seq_length,\n",
    "                    ffn_hidden=ffn_hidden,\n",
    "                    n_layers=n_layers,\n",
    "                    drop_prob=drop_prob,\n",
    "                    details=details\n",
    "                )\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000*145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/11hy697j7mv487fs334bjwvr0000gp/T/ipykernel_12909/451683020.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tr_tensor = torch.tensor(y_tr_t, dtype=torch.long)\n",
      "/var/folders/0f/11hy697j7mv487fs334bjwvr0000gp/T/ipykernel_12909/451683020.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_tensor = torch.tensor(y_val_t, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6167, Train Acc: 65.62%, Val Loss: 0.7604, Val Acc: 53.38%\n",
      "Epoch 2/50, Train Loss: 0.4615, Train Acc: 79.92%, Val Loss: 0.6742, Val Acc: 60.14%\n",
      "Epoch 3/50, Train Loss: 0.3813, Train Acc: 83.80%, Val Loss: 0.8470, Val Acc: 68.24%\n",
      "Epoch 4/50, Train Loss: 0.3299, Train Acc: 86.69%, Val Loss: 0.6418, Val Acc: 73.65%\n",
      "Epoch 5/50, Train Loss: 0.3010, Train Acc: 87.76%, Val Loss: 1.1079, Val Acc: 56.76%\n",
      "Epoch 6/50, Train Loss: 0.2964, Train Acc: 87.96%, Val Loss: 1.0577, Val Acc: 63.51%\n",
      "Epoch 7/50, Train Loss: 0.2881, Train Acc: 88.99%, Val Loss: 0.7835, Val Acc: 68.24%\n",
      "Epoch 8/50, Train Loss: 0.2389, Train Acc: 91.17%, Val Loss: 1.1693, Val Acc: 54.73%\n",
      "Epoch 9/50, Train Loss: 0.2215, Train Acc: 91.01%, Val Loss: 0.9616, Val Acc: 62.84%\n",
      "Epoch 10/50, Train Loss: 0.2071, Train Acc: 91.49%, Val Loss: 0.7692, Val Acc: 66.89%\n",
      "Epoch 11/50, Train Loss: 0.1873, Train Acc: 92.67%, Val Loss: 0.8613, Val Acc: 68.24%\n",
      "Epoch 12/50, Train Loss: 0.1818, Train Acc: 92.95%, Val Loss: 1.1582, Val Acc: 58.78%\n",
      "Epoch 13/50, Train Loss: 0.1844, Train Acc: 92.67%, Val Loss: 2.4195, Val Acc: 51.35%\n",
      "Epoch 14/50, Train Loss: 0.1798, Train Acc: 92.48%, Val Loss: 1.1259, Val Acc: 53.38%\n",
      "Epoch 15/50, Train Loss: 0.1657, Train Acc: 93.86%, Val Loss: 1.4645, Val Acc: 64.86%\n",
      "Epoch 16/50, Train Loss: 0.1636, Train Acc: 93.50%, Val Loss: 1.4487, Val Acc: 64.86%\n",
      "Epoch 17/50, Train Loss: 0.1627, Train Acc: 93.43%, Val Loss: 1.1340, Val Acc: 59.46%\n",
      "Epoch 18/50, Train Loss: 0.1498, Train Acc: 93.90%, Val Loss: 4.2282, Val Acc: 54.05%\n",
      "Epoch 19/50, Train Loss: 0.1446, Train Acc: 93.66%, Val Loss: 0.9733, Val Acc: 65.54%\n",
      "Epoch 20/50, Train Loss: 0.1457, Train Acc: 93.94%, Val Loss: 2.8192, Val Acc: 55.41%\n",
      "Epoch 21/50, Train Loss: 0.1367, Train Acc: 94.46%, Val Loss: 1.8881, Val Acc: 58.78%\n",
      "Epoch 22/50, Train Loss: 0.1257, Train Acc: 94.77%, Val Loss: 1.4362, Val Acc: 70.27%\n",
      "Epoch 23/50, Train Loss: 0.1334, Train Acc: 94.53%, Val Loss: 1.9794, Val Acc: 60.14%\n",
      "Epoch 24/50, Train Loss: 0.1210, Train Acc: 94.57%, Val Loss: 1.8919, Val Acc: 52.70%\n",
      "Epoch 25/50, Train Loss: 0.1219, Train Acc: 95.09%, Val Loss: 2.3678, Val Acc: 54.73%\n",
      "Epoch 26/50, Train Loss: 0.1234, Train Acc: 94.85%, Val Loss: 2.4864, Val Acc: 47.97%\n",
      "Epoch 27/50, Train Loss: 0.1113, Train Acc: 95.88%, Val Loss: 2.9178, Val Acc: 50.68%\n",
      "Epoch 28/50, Train Loss: 0.1086, Train Acc: 95.25%, Val Loss: 4.0086, Val Acc: 54.73%\n",
      "Epoch 29/50, Train Loss: 0.1181, Train Acc: 95.05%, Val Loss: 2.4205, Val Acc: 54.73%\n",
      "Epoch 30/50, Train Loss: 0.1078, Train Acc: 95.64%, Val Loss: 2.2802, Val Acc: 55.41%\n",
      "Epoch 31/50, Train Loss: 0.1055, Train Acc: 95.25%, Val Loss: 1.8051, Val Acc: 55.41%\n",
      "Epoch 32/50, Train Loss: 0.0930, Train Acc: 96.51%, Val Loss: 1.5238, Val Acc: 59.46%\n",
      "Epoch 33/50, Train Loss: 0.1193, Train Acc: 95.05%, Val Loss: 2.5392, Val Acc: 63.51%\n",
      "Epoch 34/50, Train Loss: 0.1031, Train Acc: 96.12%, Val Loss: 3.7390, Val Acc: 50.68%\n",
      "Epoch 35/50, Train Loss: 0.1016, Train Acc: 95.80%, Val Loss: 1.5164, Val Acc: 66.22%\n",
      "Epoch 36/50, Train Loss: 0.1033, Train Acc: 95.80%, Val Loss: 2.1028, Val Acc: 52.70%\n",
      "Early stopping triggered, best acc on val data 70.27027027027027\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Define constants\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEED = 77\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "d_model = 80\n",
    "n_head = 2\n",
    "max_len = 3000\n",
    "seq_len = 32\n",
    "ffn_hidden = 60\n",
    "n_layers = 2\n",
    "n_classes = 1\n",
    "drop_prob = 0.4\n",
    "details = False\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "patience = 14\n",
    "best_v_acc = 0\n",
    "n_noimprov = 0\n",
    "best_model_params = None\n",
    "\n",
    "y_tr_tensor = torch.tensor(y_tr_t, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_t, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Prepare data loaders\n",
    "train_dataset = TensorDataset(X_tr_t, y_tr_tensor)\n",
    "val_dataset = TensorDataset(X_val_t, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize the model\n",
    "model = Transformer(\n",
    "    device=device,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    max_len=max_len,\n",
    "    seq_len=seq_len,\n",
    "    ffn_hidden=ffn_hidden,\n",
    "    n_layers=n_layers,\n",
    "    drop_prob=drop_prob,\n",
    "    details=details\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "        # Ensure y_batch is of the correct type\n",
    "        y_batch = y_batch.float()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Compute predictions and accuracy\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        predicted = (probabilities > 0.5).float()\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "            y_batch = y_batch.float()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predicted = (probabilities > 0.5).float()\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    if train_accuracy > 90:\n",
    "        if val_accuracy > best_v_acc:\n",
    "            best_v_acc = val_accuracy\n",
    "            best_model_params = copy.deepcopy(model.state_dict())\n",
    "            n_noimprov = 0\n",
    "        else:\n",
    "            n_noimprov +=1\n",
    "                \n",
    "    if n_noimprov > patience and best_model_params: #best_model_params is not None\n",
    "        print(f\"Early stopping triggered, best acc on val data {best_v_acc}\")   \n",
    "        break \n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_params)\n",
    "model.eval()\n",
    "probabilities = torch.sigmoid(model(X_tst_t))\n",
    "predicted = (probabilities > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=predicted.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(173)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p == y_tst_t).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([296])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##to adjust for imbalanced classes\n",
    "pos_weight = len(y_tr_t) / sum(y_tr_t)  # Assumes y_tr_t is binary {0, 1}\n",
    "neg_weight = len(y_tr_t) / (len(y_tr_t) - sum(y_tr_t))\n",
    "\n",
    "# Use a tensor to represent positive and negative weights\n",
    "class_weight = torch.tensor([neg_weight, pos_weight]).to(device)\n",
    "\n",
    "# Update criterion\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=['DUSK/USDT', 'XMR/USDT', 'MATIC/USDT', 'HOT/USDT', 'DOGE/USDT', 'BAND/USDT', 'LINK/USDT', 'REN/USDT', 'WAVES/USDT', 'CVC/USDT', 'ZRX/USDT', 'IOTX/USDT', 'ONT/USDT', 'TOMO/USDT', 'CELR/USDT', 'BTC/USDT', 'DENT/USDT', 'RVN/USDT', 'THETA/USDT', 'FTT/USDT', 'IOST/USDT', 'NULS/USDT', 'ANKR/USDT', 'ETC/USDT', 'ATOM/USDT', 'ZEC/USDT', 'ETH/USDT', 'NEO/USDT', 'VET/USDT', 'ONG/USDT', 'EOS/USDT', 'FTM/USDT', 'OGN/USDT', 'XLM/USDT', 'CHZ/USDT', 'ENJ/USDT', 'IOTA/USDT', 'NKN/USDT', 'ADA/USDT', 'STX/USDT', 'QTUM/USDT', 'FET/USDT', 'ICX/USDT', 'HBAR/USDT', 'ARPA/USDT', 'BNB/USDT', 'BAT/USDT', 'BCH/USDT', 'MTL/USDT', 'OMG/USDT', 'COS/USDT', 'KAVA/USDT', 'XRP/USDT', 'LTC/USDT', 'DASH/USDT', 'ONE/USDT', 'TRX/USDT', 'ALGO/USDT', 'RLC/USDT', 'ZIL/USDT', 'XTZ/USDT', 'KEY/USDT']\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process...\n",
      "Processing series DUSK/USDT...\n",
      "norm and turning into sequences complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory_path = \"data_deep_learning/series_data\"\n",
    "\n",
    "tst_perc = 0.05\n",
    "val_perc = 0.1\n",
    "\n",
    "seq_length = 32\n",
    "d_model = 80\n",
    "n_head = 2\n",
    "max_len = 3000\n",
    "ffn_hidden = 60\n",
    "n_layers = 2\n",
    "n_classes = 1\n",
    "drop_prob = 0.4\n",
    "details = False\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "patience = 14\n",
    "model = None\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(device=device,\n",
    "                        d_model=d_model,\n",
    "                        n_head=n_head,\n",
    "                        max_len=max_len,\n",
    "                        seq_len=seq_length,\n",
    "                        ffn_hidden=ffn_hidden,\n",
    "                        n_layers=n_layers,\n",
    "                        drop_prob=drop_prob,\n",
    "                        details=details\n",
    "                    ).to(device) \n",
    "model.load_state_dict(torch.load(\"saved_model_params_6.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    print(\"Starting the process...\")\n",
    "    if file_name.endswith(\".npy\"):  \n",
    "        key = file_name.split('.')[0].replace(\"&\",\"/\")\n",
    "        print(f\"Processing series {key}...\")\n",
    "        data = np.load(directory_path+\"/\"+file_name)\n",
    "        X=data[:,:-1]\n",
    "        y=data[:,-1]\n",
    "        X=X[-3000:, 1:]\n",
    "        y=y[-3000:]\n",
    "        \n",
    "        n_X = norm_mts_with_window(X, window_size=30)    \n",
    "        n_X = create_seq_from_ts(n_X, seq_length)\n",
    "        print(f\"norm and turning into sequences complete.\")\n",
    "        n_y=y[seq_length-1:]    \n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ind_val = int(n_X.shape[0] * 0.05)\n",
    "\n",
    "X_tst= n_X[-ind_val:,:,:]\n",
    "y_tst = n_y[-ind_val:] \n",
    "\n",
    "X_tst_t = torch.tensor(X_tst, dtype=torch.float32).to(device)\n",
    "y_tst_t = torch.tensor(y_tst, dtype=torch.float32).to(device)\n",
    "\n",
    "y_tst_t = (y_tst_t +1) / 2\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tst_t)\n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    predicted = (probabilities > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pred = predicted.squeeze()\n",
    "(y_tst_t == p_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulsts=\"\"\"accuracy of model at DUSK/USDT --> 56.75675582885742\n",
    "accuracy of model at XMR/USDT --> 71.62162017822266\n",
    "accuracy of model at MATIC/USDT --> 75.67567443847656\n",
    "accuracy of model at HOT/USDT --> 37.16216278076172\n",
    "accuracy of model at DOGE/USDT --> 51.35135269165039\n",
    "accuracy of model at BAND/USDT --> 60.81081008911133\n",
    "accuracy of model at LINK/USDT --> 33.783782958984375\n",
    "accuracy of model at REN/USDT --> 64.8648681640625\n",
    "accuracy of model at WAVES/USDT --> 25.0\n",
    "accuracy of model at CVC/USDT --> 39.18918991088867\n",
    "accuracy of model at ZRX/USDT --> 31.08108139038086\n",
    "accuracy of model at IOTX/USDT --> 45.27027130126953\n",
    "accuracy of model at ONT/USDT --> 35.81081008911133\n",
    "accuracy of model at TOMO/USDT --> 72.97297668457031\n",
    "accuracy of model at CELR/USDT --> 53.378379821777344\n",
    "accuracy of model at BTC/USDT --> 73.64865112304688\n",
    "accuracy of model at DENT/USDT --> 53.378379821777344\n",
    "accuracy of model at RVN/USDT --> 45.945945739746094\n",
    "accuracy of model at THETA/USDT --> 27.027027130126953\n",
    "accuracy of model at FTT/USDT --> 39.864864349365234\n",
    "accuracy of model at IOST/USDT --> 32.43243408203125\n",
    "accuracy of model at NULS/USDT --> 44.5945930480957\n",
    "accuracy of model at ANKR/USDT --> 33.10810852050781\n",
    "accuracy of model at ETC/USDT --> 55.4054069519043\n",
    "accuracy of model at ATOM/USDT --> 44.5945930480957\n",
    "accuracy of model at ZEC/USDT --> 76.35134887695312\n",
    "accuracy of model at ETH/USDT --> 20.945945739746094\n",
    "accuracy of model at NEO/USDT --> 36.486488342285156\n",
    "accuracy of model at VET/USDT --> 43.91891860961914\n",
    "accuracy of model at ONG/USDT --> 24.324323654174805\n",
    "accuracy of model at EOS/USDT --> 36.486488342285156\n",
    "accuracy of model at FTM/USDT --> 60.135135650634766\n",
    "accuracy of model at OGN/USDT --> 62.16216278076172\n",
    "accuracy of model at XLM/USDT --> 40.5405387878418\n",
    "accuracy of model at CHZ/USDT --> 45.27027130126953\n",
    "accuracy of model at ENJ/USDT --> 38.513511657714844\n",
    "accuracy of model at IOTA/USDT --> 36.486488342285156\n",
    "accuracy of model at NKN/USDT --> 52.702701568603516\n",
    "accuracy of model at ADA/USDT --> 47.97297286987305\n",
    "accuracy of model at STX/USDT --> 58.10810852050781\n",
    "accuracy of model at QTUM/USDT --> 39.864864349365234\n",
    "accuracy of model at FET/USDT --> 72.97297668457031\n",
    "accuracy of model at ICX/USDT --> 27.027027130126953\n",
    "accuracy of model at HBAR/USDT --> 42.56756591796875\n",
    "accuracy of model at ARPA/USDT --> 26.351350784301758\n",
    "accuracy of model at BNB/USDT --> 68.9189224243164\n",
    "accuracy of model at BAT/USDT --> 34.4594612121582\n",
    "accuracy of model at BCH/USDT --> 41.89189147949219\n",
    "accuracy of model at MTL/USDT --> 40.5405387878418\n",
    "accuracy of model at OMG/USDT --> 27.70270347595215\n",
    "accuracy of model at COS/USDT --> 41.216217041015625\n",
    "accuracy of model at KAVA/USDT --> 30.405405044555664\n",
    "accuracy of model at XRP/USDT --> 49.32432556152344\n",
    "accuracy of model at LTC/USDT --> 77.70270538330078\n",
    "accuracy of model at DASH/USDT --> 26.351350784301758\n",
    "accuracy of model at ONE/USDT --> 45.27027130126953\n",
    "accuracy of model at TRX/USDT --> 45.945945739746094\n",
    "accuracy of model at ALGO/USDT --> 48.64864730834961\n",
    "accuracy of model at RLC/USDT --> 22.972972869873047\n",
    "accuracy of model at ZIL/USDT --> 25.0\n",
    "accuracy of model at XTZ/USDT --> 53.378379821777344\n",
    "accuracy of model at KEY/USDT --> 56.75675582885742\n",
    "\"\"\"\n",
    "m=resulsts.split(\" --> \")\n",
    "scores=[a.split(\"acc\")[0].replace('\\n','') for a in m][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.65170038900068"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([float(s) for s in scores])/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
