[I 2025-01-10 18:03:34,100] A new study created in memory with name: no-name-e2b907c0-3749-4afc-9232-fb0a09aaa539
/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  "drop_prob": trial.suggest_uniform("drop_prob", 0.2, 0.4),
/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  "l1_lambda": trial.suggest_loguniform("l1_lambda", 1e-5, 1e-2),
[W 2025-01-10 18:03:34,530] Trial 0 failed with parameters: {'d_model': 64, 'n_head': 2, 'ffn_hidden': 80, 'n_layers': 2, 'drop_prob': 0.2573655304659394, 'batch_size': 128, 'l1_lambda': 0.0004796257451732533} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py", line 31, in objective
    val_accuracy = train_and_evaluate_model(hyperparams, data)
  File "/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py", line 62, in train_and_evaluate_model
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/optim/adam.py", line 78, in __init__
    super().__init__(params, defaults)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/optim/optimizer.py", line 371, in __init__
    self.add_param_group(cast(dict, param_group))
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_compile.py", line 27, in inner
    import torch._dynamo
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/__init__.py", line 3, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 31, in <module>
    from torch._dynamo.utils import CompileTimeInstructionCounter
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 89, in <module>
    import torch._numpy as tnp
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_numpy/__init__.py", line 7, in <module>
    from ._ndarray import (
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_numpy/_ndarray.py", line 12, in <module>
    from . import _dtypes, _dtypes_impl, _funcs, _ufuncs, _util
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1012, in get_code
  File "<frozen importlib._bootstrap_external>", line 672, in _compile_bytecode
KeyboardInterrupt
[W 2025-01-10 18:03:34,536] Trial 0 failed with value None.
Traceback (most recent call last):
  File "/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py", line 228, in <module>
    study.optimize(partial(objective, data=coin_data, file_path=file_path), n_trials=1)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py", line 31, in objective
    val_accuracy = train_and_evaluate_model(hyperparams, data)
  File "/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py", line 62, in train_and_evaluate_model
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/optim/adam.py", line 78, in __init__
    super().__init__(params, defaults)
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/optim/optimizer.py", line 371, in __init__
    self.add_param_group(cast(dict, param_group))
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_compile.py", line 27, in inner
    import torch._dynamo
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/__init__.py", line 3, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 31, in <module>
    from torch._dynamo.utils import CompileTimeInstructionCounter
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 89, in <module>
    import torch._numpy as tnp
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_numpy/__init__.py", line 7, in <module>
    from ._ndarray import (
  File "/home/capi1206/miniconda3/envs/timeseries/lib/python3.10/site-packages/torch/_numpy/_ndarray.py", line 12, in <module>
    from . import _dtypes, _dtypes_impl, _funcs, _ufuncs, _util
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1012, in get_code
  File "<frozen importlib._bootstrap_external>", line 672, in _compile_bytecode
KeyboardInterrupt
nohup: ignoring input
[I 2025-01-10 18:03:54,468] A new study created in memory with name: no-name-326e392e-86c4-4c54-a2e8-6b1080c48b0f
/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  "drop_prob": trial.suggest_uniform("drop_prob", 0.2, 0.4),
/home/capi1206/Documents/deepL_tests/few_series/bay_optim_hyperparam.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  "l1_lambda": trial.suggest_loguniform("l1_lambda", 1e-5, 1e-2),
[I 2025-01-10 19:44:26,719] Trial 0 finished with value: 57.207644962747004 and parameters: {'d_model': 64, 'n_head': 2, 'ffn_hidden': 80, 'n_layers': 2, 'drop_prob': 0.29922192572433093, 'batch_size': 64, 'l1_lambda': 0.009816975854936754}. Best is trial 0 with value: 57.207644962747004.
   Total best acc changed to 50.016196954972465,  
                            at epoch 0/30
     and coin 19
  Epoch 1/30, 
  Train Loss: 0.0341, Train Acc: 56.04%, 
  Val Loss: 0.7677, Val Acc: 50.02% 

   Total best acc changed to 52.899254940071266,  
                            at epoch 1/30
     and coin 19
   Total best acc changed to 55.19922254616132,  
                            at epoch 6/30
     and coin 19
   Total best acc changed to 55.52316164561063,  
                            at epoch 8/30
     and coin 19
  Epoch 11/30, 
  Train Loss: 0.0033, Train Acc: 59.70%, 
  Val Loss: 1.1805, Val Acc: 51.99% 

   Total best acc changed to 56.235827664399096,  
                            at epoch 12/30
     and coin 19
  Epoch 21/30, 
  Train Loss: 0.0023, Train Acc: 63.92%, 
  Val Loss: 1.4801, Val Acc: 50.24% 

  Early stopping triggered, with best val acc: 56.235827664399096, st
  Epoch 1/30, 
  Train Loss: 0.0044, Train Acc: 55.42%, 
  Val Loss: 2.5388, Val Acc: 46.36% 

  Epoch 11/30, 
  Train Loss: 0.0021, Train Acc: 58.23%, 
  Val Loss: 7.0716, Val Acc: 46.84% 

  Early stopping triggered, with best val acc: 47.45707806932297, st
  Epoch 1/30, 
  Train Loss: 0.0048, Train Acc: 49.59%, 
  Val Loss: 0.7634, Val Acc: 49.34% 

  Epoch 11/30, 
  Train Loss: 0.0022, Train Acc: 61.13%, 
  Val Loss: 1.7538, Val Acc: 48.36% 

  Early stopping triggered, with best val acc: 51.34434726271461, st
  Epoch 1/30, 
  Train Loss: 0.0056, Train Acc: 48.59%, 
  Val Loss: 0.8808, Val Acc: 50.89% 

  Epoch 11/30, 
  Train Loss: 0.0035, Train Acc: 58.18%, 
  Val Loss: 1.1880, Val Acc: 49.43% 

  Epoch 21/30, 
  Train Loss: 0.0023, Train Acc: 61.39%, 
  Val Loss: 1.1903, Val Acc: 53.13% 

  Epoch 1/30, 
  Train Loss: 0.0042, Train Acc: 57.10%, 
  Val Loss: 0.9186, Val Acc: 48.43% 

  Epoch 11/30, 
  Train Loss: 0.0019, Train Acc: 62.63%, 
  Val Loss: 1.2834, Val Acc: 50.24% 

  Early stopping triggered, with best val acc: 53.67670877874959, st
  Epoch 1/30, 
  Train Loss: 0.0034, Train Acc: 49.22%, 
  Val Loss: 0.6331, Val Acc: 44.31% 

  Epoch 11/30, 
  Train Loss: 0.0020, Train Acc: 59.43%, 
  Val Loss: 0.9499, Val Acc: 47.17% 

  Epoch 21/30, 
  Train Loss: 0.0011, Train Acc: 62.24%, 
  Val Loss: 2.0892, Val Acc: 48.23% 

  Epoch 1/30, 
  Train Loss: 0.0050, Train Acc: 52.65%, 
  Val Loss: 0.7386, Val Acc: 47.00% 

  Epoch 11/30, 
  Train Loss: 0.0023, Train Acc: 59.73%, 
  Val Loss: 1.2474, Val Acc: 50.37% 

  Early stopping triggered, with best val acc: 52.83446712018141, st
  Epoch 1/30, 
  Train Loss: 0.0046, Train Acc: 55.09%, 
  Val Loss: 1.3540, Val Acc: 48.88% 

  Epoch 11/30, 
  Train Loss: 0.0019, Train Acc: 63.49%, 
  Val Loss: 2.3167, Val Acc: 49.21% 

  Epoch 21/30, 
  Train Loss: 0.0015, Train Acc: 63.69%, 
  Val Loss: 1.9256, Val Acc: 49.56% 

  Epoch 1/30, 
  Train Loss: 0.0039, Train Acc: 52.12%, 
  Val Loss: 0.9793, Val Acc: 46.68% 

  Epoch 11/30, 
  Train Loss: 0.0020, Train Acc: 60.95%, 
  Val Loss: 1.5063, Val Acc: 51.02% 

  Epoch 21/30, 
  Train Loss: 0.0016, Train Acc: 61.39%, 
  Val Loss: 1.6794, Val Acc: 50.50% 

  Early stopping triggered, with best val acc: 51.02040816326531, st
  Epoch 1/30, 
  Train Loss: 0.0046, Train Acc: 55.58%, 
  Val Loss: 1.4677, Val Acc: 46.65% 

   Total best acc changed to 57.207644962747004,  
                            at epoch 6/30
     and coin 19
  Epoch 11/30, 
  Train Loss: 0.0022, Train Acc: 64.71%, 
  Val Loss: 2.1785, Val Acc: 53.51% 

   Early stopping triggered, with best val acc: 57.207644962747004, nd
  Epoch 1/30, 
  Train Loss: 0.0044, Train Acc: 56.94%, 
  Val Loss: 0.6597, Val Acc: 53.39% 

  Epoch 11/30, 
  Train Loss: 0.0019, Train Acc: 61.64%, 
  Val Loss: 1.5364, Val Acc: 50.92% 

  Early stopping triggered, with best val acc: 53.385163589245224, st
  Epoch 1/30, 
  Train Loss: 0.0055, Train Acc: 50.41%, 
  Val Loss: 0.8320, Val Acc: 49.63% 

  Epoch 11/30, 
  Train Loss: 0.0029, Train Acc: 57.91%, 
  Val Loss: 2.2370, Val Acc: 46.10% 

  Epoch 21/30, 
  Train Loss: 0.0021, Train Acc: 58.58%, 
  Val Loss: 1.7931, Val Acc: 48.53% 

  Early stopping triggered, with best val acc: 51.31195335276968, st
  Epoch 1/30, 
  Train Loss: 0.0041, Train Acc: 50.16%, 
  Val Loss: 1.0369, Val Acc: 48.62% 

  Epoch 11/30, 
  Train Loss: 0.0017, Train Acc: 63.76%, 
  Val Loss: 1.4548, Val Acc: 51.93% 

  Epoch 21/30, 
  Train Loss: 0.0012, Train Acc: 63.92%, 
  Val Loss: 1.8215, Val Acc: 49.37% 

  Epoch 1/30, 
  Train Loss: 0.0040, Train Acc: 55.51%, 
  Val Loss: 1.7901, Val Acc: 48.20% 

  Epoch 11/30, 
  Train Loss: 0.0013, Train Acc: 60.56%, 
  Val Loss: 3.3311, Val Acc: 45.77% 

  Early stopping triggered, with best val acc: 48.81762228701004, st
  Epoch 1/30, 
  Train Loss: 0.0042, Train Acc: 50.90%, 
  Val Loss: 0.8599, Val Acc: 54.75% 

  Epoch 11/30, 
  Train Loss: 0.0023, Train Acc: 61.96%, 
  Val Loss: 2.5309, Val Acc: 50.60% 

  Early stopping triggered, with best val acc: 54.745707806932295, st
  Epoch 1/30, 
  Train Loss: 0.0050, Train Acc: 54.86%, 
  Val Loss: 1.0685, Val Acc: 49.34% 

  Epoch 11/30, 
  Train Loss: 0.0027, Train Acc: 62.54%, 
  Val Loss: 1.4233, Val Acc: 51.60% 

  Early stopping triggered, with best val acc: 53.64431486880466, st
  Epoch 1/30, 
  Train Loss: 0.0038, Train Acc: 56.43%, 
  Val Loss: 0.7288, Val Acc: 52.28% 

  Epoch 11/30, 
  Train Loss: 0.0023, Train Acc: 61.09%, 
  Val Loss: 0.9328, Val Acc: 53.03% 

  Early stopping triggered, with best val acc: 54.84288953676709, st
  Epoch 1/30, 
  Train Loss: 0.0048, Train Acc: 50.76%, 
  Val Loss: 0.7253, Val Acc: 45.93% 

  Epoch 11/30, 
  Train Loss: 0.0027, Train Acc: 56.41%, 
  Val Loss: 1.9139, Val Acc: 48.82% 

  Epoch 21/30, 
  Train Loss: 0.0019, Train Acc: 59.82%, 
  Val Loss: 1.5181, Val Acc: 47.68% 

  Early stopping triggered, with best val acc: 48.81762228701004, st
  Epoch 1/30, 
  Train Loss: 0.0050, Train Acc: 47.37%, 
  Val Loss: 0.7977, Val Acc: 51.70% 

  Epoch 11/30, 
  Train Loss: 0.0029, Train Acc: 58.44%, 
  Val Loss: 1.0967, Val Acc: 50.15% 

  Early stopping triggered, with best val acc: 55.652737285390344, st
  Epoch 1/30, 
  Train Loss: 0.0045, Train Acc: 54.59%, 
  Val Loss: 0.9959, Val Acc: 51.41% 

  Epoch 11/30, 
  Train Loss: 0.0024, Train Acc: 60.95%, 
  Val Loss: 1.6107, Val Acc: 50.89% 

  Epoch 21/30, 
  Train Loss: 0.0017, Train Acc: 61.48%, 
  Val Loss: 1.8492, Val Acc: 52.41% 

  Early stopping triggered, with best val acc: 54.0006478781989, st
  Epoch 1/30, 
  Train Loss: 0.0043, Train Acc: 51.71%, 
  Val Loss: 1.0726, Val Acc: 51.05% 

  Epoch 11/30, 
  Train Loss: 0.0023, Train Acc: 59.73%, 
  Val Loss: 1.4515, Val Acc: 49.66% 

  Early stopping triggered, with best val acc: 52.704891480401685, st
Best hyperparameters: {'d_model': 64, 'n_head': 2, 'ffn_hidden': 80, 'n_layers': 2, 'drop_prob': 0.29922192572433093, 'batch_size': 64, 'l1_lambda': 0.009816975854936754}

Best validation accuracy: 57.207644962747004

This was the accuracy doing PCE with the initial series, leaving 52 out of 145.

